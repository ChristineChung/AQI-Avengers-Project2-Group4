{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 191,
     "status": "ok",
     "timestamp": 1719952015021,
     "user": {
      "displayName": "Chearine P",
      "userId": "14540736819828601911"
     },
     "user_tz": 240
    },
    "id": "FmHYGorUCvSb"
   },
   "outputs": [],
   "source": [
    "# Importing the required libraries and dependencies\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 40933,
     "status": "ok",
     "timestamp": 1719962921818,
     "user": {
      "displayName": "Chearine P",
      "userId": "14540736819828601911"
     },
     "user_tz": 240
    },
    "id": "92oQiUNVDeas",
    "outputId": "4dd86107-74cb-4839-a2d9-e7ef0a8a9d0b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# *FOR GOOGLE COLAB* - Import the `files` library to allow files upload\n",
    "#from google.colab import files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "executionInfo": {
     "elapsed": 43296,
     "status": "ok",
     "timestamp": 1719952071774,
     "user": {
      "displayName": "Chearine P",
      "userId": "14540736819828601911"
     },
     "user_tz": 240
    },
    "id": "hIv-oqiCGxEJ",
    "outputId": "6998cf50-b3d0-42ad-c5f0-52f38c0aa541"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-7d4c1141-da9d-4a3a-b4f9-5deb5f567cfc\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-7d4c1141-da9d-4a3a-b4f9-5deb5f567cfc\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script>// Copyright 2017 Google LLC\n",
       "//\n",
       "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
       "// you may not use this file except in compliance with the License.\n",
       "// You may obtain a copy of the License at\n",
       "//\n",
       "//      http://www.apache.org/licenses/LICENSE-2.0\n",
       "//\n",
       "// Unless required by applicable law or agreed to in writing, software\n",
       "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
       "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
       "// See the License for the specific language governing permissions and\n",
       "// limitations under the License.\n",
       "\n",
       "/**\n",
       " * @fileoverview Helpers for google.colab Python module.\n",
       " */\n",
       "(function(scope) {\n",
       "function span(text, styleAttributes = {}) {\n",
       "  const element = document.createElement('span');\n",
       "  element.textContent = text;\n",
       "  for (const key of Object.keys(styleAttributes)) {\n",
       "    element.style[key] = styleAttributes[key];\n",
       "  }\n",
       "  return element;\n",
       "}\n",
       "\n",
       "// Max number of bytes which will be uploaded at a time.\n",
       "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
       "\n",
       "function _uploadFiles(inputId, outputId) {\n",
       "  const steps = uploadFilesStep(inputId, outputId);\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  // Cache steps on the outputElement to make it available for the next call\n",
       "  // to uploadFilesContinue from Python.\n",
       "  outputElement.steps = steps;\n",
       "\n",
       "  return _uploadFilesContinue(outputId);\n",
       "}\n",
       "\n",
       "// This is roughly an async generator (not supported in the browser yet),\n",
       "// where there are multiple asynchronous steps and the Python side is going\n",
       "// to poll for completion of each step.\n",
       "// This uses a Promise to block the python side on completion of each step,\n",
       "// then passes the result of the previous step as the input to the next step.\n",
       "function _uploadFilesContinue(outputId) {\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  const steps = outputElement.steps;\n",
       "\n",
       "  const next = steps.next(outputElement.lastPromiseValue);\n",
       "  return Promise.resolve(next.value.promise).then((value) => {\n",
       "    // Cache the last promise value to make it available to the next\n",
       "    // step of the generator.\n",
       "    outputElement.lastPromiseValue = value;\n",
       "    return next.value.response;\n",
       "  });\n",
       "}\n",
       "\n",
       "/**\n",
       " * Generator function which is called between each async step of the upload\n",
       " * process.\n",
       " * @param {string} inputId Element ID of the input file picker element.\n",
       " * @param {string} outputId Element ID of the output display.\n",
       " * @return {!Iterable<!Object>} Iterable of next steps.\n",
       " */\n",
       "function* uploadFilesStep(inputId, outputId) {\n",
       "  const inputElement = document.getElementById(inputId);\n",
       "  inputElement.disabled = false;\n",
       "\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  outputElement.innerHTML = '';\n",
       "\n",
       "  const pickedPromise = new Promise((resolve) => {\n",
       "    inputElement.addEventListener('change', (e) => {\n",
       "      resolve(e.target.files);\n",
       "    });\n",
       "  });\n",
       "\n",
       "  const cancel = document.createElement('button');\n",
       "  inputElement.parentElement.appendChild(cancel);\n",
       "  cancel.textContent = 'Cancel upload';\n",
       "  const cancelPromise = new Promise((resolve) => {\n",
       "    cancel.onclick = () => {\n",
       "      resolve(null);\n",
       "    };\n",
       "  });\n",
       "\n",
       "  // Wait for the user to pick the files.\n",
       "  const files = yield {\n",
       "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
       "    response: {\n",
       "      action: 'starting',\n",
       "    }\n",
       "  };\n",
       "\n",
       "  cancel.remove();\n",
       "\n",
       "  // Disable the input element since further picks are not allowed.\n",
       "  inputElement.disabled = true;\n",
       "\n",
       "  if (!files) {\n",
       "    return {\n",
       "      response: {\n",
       "        action: 'complete',\n",
       "      }\n",
       "    };\n",
       "  }\n",
       "\n",
       "  for (const file of files) {\n",
       "    const li = document.createElement('li');\n",
       "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
       "    li.append(span(\n",
       "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
       "        `last modified: ${\n",
       "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
       "                                    'n/a'} - `));\n",
       "    const percent = span('0% done');\n",
       "    li.appendChild(percent);\n",
       "\n",
       "    outputElement.appendChild(li);\n",
       "\n",
       "    const fileDataPromise = new Promise((resolve) => {\n",
       "      const reader = new FileReader();\n",
       "      reader.onload = (e) => {\n",
       "        resolve(e.target.result);\n",
       "      };\n",
       "      reader.readAsArrayBuffer(file);\n",
       "    });\n",
       "    // Wait for the data to be ready.\n",
       "    let fileData = yield {\n",
       "      promise: fileDataPromise,\n",
       "      response: {\n",
       "        action: 'continue',\n",
       "      }\n",
       "    };\n",
       "\n",
       "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
       "    let position = 0;\n",
       "    do {\n",
       "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
       "      const chunk = new Uint8Array(fileData, position, length);\n",
       "      position += length;\n",
       "\n",
       "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
       "      yield {\n",
       "        response: {\n",
       "          action: 'append',\n",
       "          file: file.name,\n",
       "          data: base64,\n",
       "        },\n",
       "      };\n",
       "\n",
       "      let percentDone = fileData.byteLength === 0 ?\n",
       "          100 :\n",
       "          Math.round((position / fileData.byteLength) * 100);\n",
       "      percent.textContent = `${percentDone}% done`;\n",
       "\n",
       "    } while (position < fileData.byteLength);\n",
       "  }\n",
       "\n",
       "  // All done.\n",
       "  yield {\n",
       "    response: {\n",
       "      action: 'complete',\n",
       "    }\n",
       "  };\n",
       "}\n",
       "\n",
       "scope.google = scope.google || {};\n",
       "scope.google.colab = scope.google.colab || {};\n",
       "scope.google.colab._files = {\n",
       "  _uploadFiles,\n",
       "  _uploadFilesContinue,\n",
       "};\n",
       "})(self);\n",
       "</script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving consolidated_seven_ny_counties.csv to consolidated_seven_ny_counties.csv\n"
     ]
    }
   ],
   "source": [
    "# *FOR GOOGLE COLAB* - Upload \"consolidated_seven_ny_counties.csv\" into Colab, then store in a DataFrame\n",
    "#uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "executionInfo": {
     "elapsed": 894,
     "status": "ok",
     "timestamp": 1719956552871,
     "user": {
      "displayName": "Chearine P",
      "userId": "14540736819828601911"
     },
     "user_tz": 240
    },
    "id": "WTW0eQ_kHYEw",
    "outputId": "8f8f9758-7634-430c-8d07-becd57466456"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Resources/consolidated_seven_ny_counties.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Storing the data in a Pandas DataFrame\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Setting the \"date_local\" column as the Datetime Index.\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m new_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mResources/consolidated_seven_ny_counties.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdate_local\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlow_memory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[0;32m      9\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Preview the dataset\u001b[39;00m\n\u001b[0;32m     12\u001b[0m new_df\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dev\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    945\u001b[0m )\n\u001b[0;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dev\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    608\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    610\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 611\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dev\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1445\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1447\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dev\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1703\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1704\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1705\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1706\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1707\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1708\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1709\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1710\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1711\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1712\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1713\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1714\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1715\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1716\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dev\\lib\\site-packages\\pandas\\io\\common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    859\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    860\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    861\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    862\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 863\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    864\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    865\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    866\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    867\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    868\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    869\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    871\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    872\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Resources/consolidated_seven_ny_counties.csv'"
     ]
    }
   ],
   "source": [
    "# Storing the data in a Pandas DataFrame\n",
    "# Setting the \"date_local\" column as the Datetime Index.\n",
    "\n",
    "new_df = pd.read_csv(\n",
    "    \"Resources/consolidated_seven_ny_counties.csv\",\n",
    "    index_col='date_local',\n",
    "    low_memory=False,\n",
    "    parse_dates=True\n",
    ")\n",
    "\n",
    "# Preview the dataset\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 127,
     "status": "ok",
     "timestamp": 1719956556787,
     "user": {
      "displayName": "Chearine P",
      "userId": "14540736819828601911"
     },
     "user_tz": 240
    },
    "id": "Ygw8xZNtIpt5",
    "outputId": "889dee5f-0fd9-4b8f-c744-8e30991f5a6a"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'new_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mnew_df\u001b[49m\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[1;31mNameError\u001b[0m: name 'new_df' is not defined"
     ]
    }
   ],
   "source": [
    "new_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display options to show all rows\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 156,
     "status": "ok",
     "timestamp": 1719956558337,
     "user": {
      "displayName": "Chearine P",
      "userId": "14540736819828601911"
     },
     "user_tz": 240
    },
    "id": "vNwWKrQCJEuZ",
    "outputId": "f6bef4f0-59a7-48ca-e63f-38cf94f52542"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['county_code', 'parameter_code', 'parameter', 'latitude', 'longitude',\n",
       "       'sample_duration_code', 'units_of_measure', 'observation_count',\n",
       "       'validity_indicator', 'arithmetic_mean',\n",
       "       ...\n",
       "       'units_of_measure_81102', 'observation_count_81102',\n",
       "       'validity_indicator_81102', 'arithmetic_mean_81102',\n",
       "       'first_max_value_81102', 'first_max_hour_81102', 'aqi_81102',\n",
       "       'county_81102', 'city_81102', 'aqi_max'],\n",
       "      dtype='object', length=106)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 330
    },
    "executionInfo": {
     "elapsed": 158,
     "status": "ok",
     "timestamp": 1719956576012,
     "user": {
      "displayName": "Chearine P",
      "userId": "14540736819828601911"
     },
     "user_tz": 240
    },
    "id": "BoPvy1w6JNXI",
    "outputId": "08a1a6ae-d762-4f36-807c-d16f1ed8c5aa"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>county</th>\n",
       "      <th>aqi_42101</th>\n",
       "      <th>aqi_42401</th>\n",
       "      <th>aqi_44201</th>\n",
       "      <th>aqi_42602</th>\n",
       "      <th>aqi_88502</th>\n",
       "      <th>aqi_max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date_local</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-01-01</th>\n",
       "      <td>40.81551</td>\n",
       "      <td>-73.88553</td>\n",
       "      <td>Bronx</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.8</td>\n",
       "      <td>22.000</td>\n",
       "      <td>23.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-02</th>\n",
       "      <td>40.81551</td>\n",
       "      <td>-73.88553</td>\n",
       "      <td>Bronx</td>\n",
       "      <td>6.5</td>\n",
       "      <td>11.4</td>\n",
       "      <td>21.000</td>\n",
       "      <td>26.5</td>\n",
       "      <td>60.0</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-03</th>\n",
       "      <td>40.81551</td>\n",
       "      <td>-73.88553</td>\n",
       "      <td>Bronx</td>\n",
       "      <td>6.5</td>\n",
       "      <td>15.0</td>\n",
       "      <td>19.375</td>\n",
       "      <td>35.5</td>\n",
       "      <td>59.0</td>\n",
       "      <td>59.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-04</th>\n",
       "      <td>40.81551</td>\n",
       "      <td>-73.88553</td>\n",
       "      <td>Bronx</td>\n",
       "      <td>7.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>19.000</td>\n",
       "      <td>36.5</td>\n",
       "      <td>60.0</td>\n",
       "      <td>64.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-05</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.2</td>\n",
       "      <td>23.500</td>\n",
       "      <td>41.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            latitude  longitude county  aqi_42101  aqi_42401  aqi_44201  \\\n",
       "date_local                                                                \n",
       "2013-01-01  40.81551  -73.88553  Bronx        4.5        9.8     22.000   \n",
       "2013-01-02  40.81551  -73.88553  Bronx        6.5       11.4     21.000   \n",
       "2013-01-03  40.81551  -73.88553  Bronx        6.5       15.0     19.375   \n",
       "2013-01-04  40.81551  -73.88553  Bronx        7.0       13.0     19.000   \n",
       "2013-01-05       NaN        NaN    NaN        8.0       10.2     23.500   \n",
       "\n",
       "            aqi_42602  aqi_88502  aqi_max  \n",
       "date_local                                 \n",
       "2013-01-01       23.0       52.0     52.0  \n",
       "2013-01-02       26.5       60.0     60.0  \n",
       "2013-01-03       35.5       59.0     59.0  \n",
       "2013-01-04       36.5       60.0     64.5  \n",
       "2013-01-05       41.5        NaN     41.5  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dropping all unnecessary columns and displaying DataFrame\n",
    "dropped_columns_df = new_df [['latitude_88502', 'longitude_88502','county_88502', 'aqi','aqi_42401','aqi_44201','aqi_42602','aqi_88502','aqi_max' ]].copy()\n",
    "dropped_columns_df.rename(columns={\"aqi\": \"aqi_42101\", 'latitude_88502': 'latitude', 'longitude_88502': 'longitude', 'county_88502': 'county'}, inplace=True)\n",
    "dropped_columns_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 131,
     "status": "ok",
     "timestamp": 1719956580354,
     "user": {
      "displayName": "Chearine P",
      "userId": "14540736819828601911"
     },
     "user_tz": 240
    },
    "id": "bbjkna8bNYQg",
    "outputId": "7cdbd0f0-7198-48af-bb55-c39a9812eacc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "latitude       692\n",
       "longitude      692\n",
       "county         692\n",
       "aqi_42101     7180\n",
       "aqi_42401    17756\n",
       "aqi_44201    12579\n",
       "aqi_42602    19335\n",
       "aqi_88502      692\n",
       "aqi_max          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View sum of null values per column\n",
    "dropped_columns_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 147,
     "status": "ok",
     "timestamp": 1719956582540,
     "user": {
      "displayName": "Chearine P",
      "userId": "14540736819828601911"
     },
     "user_tz": 240
    },
    "id": "R47qGk65Xs6W",
    "outputId": "f7b4eaa7-1df1-4503-d530-7bf1a21cc0dd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chearine\\AppData\\Local\\Temp\\ipykernel_25228\\2718495195.py:2: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  dropped_columns_df['latitude'] = dropped_columns_df['latitude'].fillna(method='ffill')\n",
      "C:\\Users\\Chearine\\AppData\\Local\\Temp\\ipykernel_25228\\2718495195.py:3: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  dropped_columns_df['longitude'] = dropped_columns_df['longitude'].fillna(method='ffill')\n",
      "C:\\Users\\Chearine\\AppData\\Local\\Temp\\ipykernel_25228\\2718495195.py:4: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  dropped_columns_df['county'] = dropped_columns_df['county'].fillna(method='ffill')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "latitude         0\n",
       "longitude        0\n",
       "county           0\n",
       "aqi_42101     7180\n",
       "aqi_42401    17756\n",
       "aqi_44201    12579\n",
       "aqi_42602    19335\n",
       "aqi_88502      692\n",
       "aqi_max          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fill in blanks in lat, long, and city columns using forward fill\n",
    "dropped_columns_df['latitude'] = dropped_columns_df['latitude'].fillna(method='ffill')\n",
    "dropped_columns_df['longitude'] = dropped_columns_df['longitude'].fillna(method='ffill')\n",
    "dropped_columns_df['county'] = dropped_columns_df['county'].fillna(method='ffill')\n",
    "dropped_columns_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12447,
     "status": "ok",
     "timestamp": 1719956597950,
     "user": {
      "displayName": "Chearine P",
      "userId": "14540736819828601911"
     },
     "user_tz": 240
    },
    "id": "rnLtLsbMYT7b",
    "outputId": "167fb8e6-773b-4248-e08a-eff566cfaa83"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chearine\\AppData\\Local\\Temp\\ipykernel_25228\\2345176665.py:8: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  dropped_columns_df['aqi_42101'] = dropped_columns_df['aqi_42101'].fillna(method='ffill').fillna(method='bfill')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values before imputation:\n",
      "latitude         0\n",
      "longitude        0\n",
      "county           0\n",
      "aqi_42101        0\n",
      "aqi_42401    17756\n",
      "aqi_44201    12579\n",
      "aqi_42602    19335\n",
      "aqi_88502      692\n",
      "aqi_max          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#To fill the missing AQI_42101 score values in the provided code, we used imputation techniques.\n",
    "#Based on the nature of air quality data, which often has temporal and spatial dependencies, we useds a combination of methods.\n",
    "\n",
    "#1. Forward fill and backward fill:\n",
    "# First, we’ll use forward fill and backward fill methods to handle missing values that occur in time series data.\n",
    "\n",
    "# Forward fill and backward fill\n",
    "dropped_columns_df['aqi_42101'] = dropped_columns_df['aqi_42101'].fillna(method='ffill').fillna(method='bfill')\n",
    "\n",
    "#2. Interpolation:\n",
    "#For any remaining missing values, we can use interpolation, which is particularly useful for time series data.\n",
    "dropped_columns_df['aqi_42101'] = dropped_columns_df['aqi_42101'].interpolate(method='time')\n",
    "\n",
    "#3. Mean imputation by category:\n",
    "# If there are still missing values after the above steps, we can use mean imputation based on categories like ‘County’ and ‘date_local’.\n",
    "# Group by relevant categories and fill with mean\n",
    "dropped_columns_df['aqi_42101'] = dropped_columns_df.groupby(['county','date_local'])['aqi_42101'].transform(lambda x: x.fillna(x.mean()))\n",
    "\n",
    "# 4. Overall mean imputation:\n",
    "# As a last resort, fill any remaining missing values with the overall mean.\n",
    "dropped_columns_df['aqi_42101'] = dropped_columns_df['aqi_42101'].fillna(dropped_columns_df['aqi_42101'].mean())\n",
    "\n",
    "# # Check for missing values\n",
    "print(\"Missing values before imputation:\")\n",
    "print(dropped_columns_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vzv31nRqZ-ns"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11467,
     "status": "ok",
     "timestamp": 1719956709539,
     "user": {
      "displayName": "Chearine P",
      "userId": "14540736819828601911"
     },
     "user_tz": 240
    },
    "id": "3ilPIgWnZ_Ov",
    "outputId": "7dcaeb96-d153-4f47-df9f-5d098c4a67bc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chearine\\AppData\\Local\\Temp\\ipykernel_25228\\3272852146.py:8: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  dropped_columns_df['aqi_42401'] = dropped_columns_df['aqi_42401'].fillna(method='ffill').fillna(method='bfill')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values before imputation:\n",
      "latitude         0\n",
      "longitude        0\n",
      "county           0\n",
      "aqi_42101        0\n",
      "aqi_42401        0\n",
      "aqi_44201    12579\n",
      "aqi_42602    19335\n",
      "aqi_88502      692\n",
      "aqi_max          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#To fill the missing AQI_42401 score values in the provided code, we used imputation techniques.\n",
    "#Based on the nature of air quality data, which often has temporal and spatial dependencies, we useds a combination of methods.\n",
    "\n",
    "#1. Forward fill and backward fill:\n",
    "# First, we’ll use forward fill and backward fill methods to handle missing values that occur in time series data.\n",
    "\n",
    "# Forward fill and backward fill\n",
    "dropped_columns_df['aqi_42401'] = dropped_columns_df['aqi_42401'].fillna(method='ffill').fillna(method='bfill')\n",
    "\n",
    "#2. Interpolation:\n",
    "#For any remaining missing values, we can use interpolation, which is particularly useful for time series data.\n",
    "dropped_columns_df['aqi_42401'] = dropped_columns_df['aqi_42401'].interpolate(method='time')\n",
    "\n",
    "#3. Mean imputation by category:\n",
    "# If there are still missing values after the above steps, we can use mean imputation based on categories like ‘County’ and ‘date_local’.\n",
    "# Group by relevant categories and fill with mean\n",
    "dropped_columns_df['aqi_42401'] = dropped_columns_df.groupby(['county','date_local'])['aqi_42401'].transform(lambda x: x.fillna(x.mean()))\n",
    "\n",
    "# 4. Overall mean imputation:\n",
    "# As a last resort, fill any remaining missing values with the overall mean.\n",
    "dropped_columns_df['aqi_42401'] = dropped_columns_df['aqi_42401'].fillna(dropped_columns_df['aqi_42401'].mean())\n",
    "\n",
    "# # Check for missing values\n",
    "print(\"Missing values before imputation:\")\n",
    "print(dropped_columns_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VPLxzkTQaMql"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12249,
     "status": "ok",
     "timestamp": 1719956758364,
     "user": {
      "displayName": "Chearine P",
      "userId": "14540736819828601911"
     },
     "user_tz": 240
    },
    "id": "GpJTy5-oaNHh",
    "outputId": "dd3b62e5-bc7e-44be-8e56-fcf9adac8417"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chearine\\AppData\\Local\\Temp\\ipykernel_25228\\28589287.py:8: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  dropped_columns_df['aqi_44201'] = dropped_columns_df['aqi_44201'].fillna(method='ffill').fillna(method='bfill')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values before imputation:\n",
      "latitude         0\n",
      "longitude        0\n",
      "county           0\n",
      "aqi_42101        0\n",
      "aqi_42401        0\n",
      "aqi_44201        0\n",
      "aqi_42602    19335\n",
      "aqi_88502      692\n",
      "aqi_max          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#To fill the missing AQI_44201 score values in the provided code, we used imputation techniques.\n",
    "#Based on the nature of air quality data, which often has temporal and spatial dependencies, we useds a combination of methods.\n",
    "\n",
    "#1. Forward fill and backward fill:\n",
    "# First, we’ll use forward fill and backward fill methods to handle missing values that occur in time series data.\n",
    "\n",
    "# Forward fill and backward fill\n",
    "dropped_columns_df['aqi_44201'] = dropped_columns_df['aqi_44201'].fillna(method='ffill').fillna(method='bfill')\n",
    "\n",
    "#2. Interpolation:\n",
    "#For any remaining missing values, we can use interpolation, which is particularly useful for time series data.\n",
    "dropped_columns_df['aqi_44201'] = dropped_columns_df['aqi_44201'].interpolate(method='time')\n",
    "\n",
    "#3. Mean imputation by category:\n",
    "# If there are still missing values after the above steps, we can use mean imputation based on categories like ‘County’ and ‘date_local’.\n",
    "# Group by relevant categories and fill with mean\n",
    "dropped_columns_df['aqi_44201'] = dropped_columns_df.groupby(['county','date_local'])['aqi_44201'].transform(lambda x: x.fillna(x.mean()))\n",
    "\n",
    "# 4. Overall mean imputation:\n",
    "# As a last resort, fill any remaining missing values with the overall mean.\n",
    "dropped_columns_df['aqi_44201'] = dropped_columns_df['aqi_44201'].fillna(dropped_columns_df['aqi_44201'].mean())\n",
    "\n",
    "# # Check for missing values\n",
    "print(\"Missing values before imputation:\")\n",
    "print(dropped_columns_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ibCx_-ytaW18"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11346,
     "status": "ok",
     "timestamp": 1719956809398,
     "user": {
      "displayName": "Chearine P",
      "userId": "14540736819828601911"
     },
     "user_tz": 240
    },
    "id": "_Dl0Y6X8aZdl",
    "outputId": "34c356a6-d936-46c4-b5a7-76fd337a6a2c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chearine\\AppData\\Local\\Temp\\ipykernel_25228\\2642964399.py:8: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  dropped_columns_df['aqi_42602'] = dropped_columns_df['aqi_42602'].fillna(method='ffill').fillna(method='bfill')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values before imputation:\n",
      "latitude       0\n",
      "longitude      0\n",
      "county         0\n",
      "aqi_42101      0\n",
      "aqi_42401      0\n",
      "aqi_44201      0\n",
      "aqi_42602      0\n",
      "aqi_88502    692\n",
      "aqi_max        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#To fill the missing AQI_42602 score values in the provided code, we used imputation techniques.\n",
    "#Based on the nature of air quality data, which often has temporal and spatial dependencies, we useds a combination of methods.\n",
    "\n",
    "#1. Forward fill and backward fill:\n",
    "# First, we’ll use forward fill and backward fill methods to handle missing values that occur in time series data.\n",
    "\n",
    "# Forward fill and backward fill\n",
    "dropped_columns_df['aqi_42602'] = dropped_columns_df['aqi_42602'].fillna(method='ffill').fillna(method='bfill')\n",
    "\n",
    "#2. Interpolation:\n",
    "#For any remaining missing values, we can use interpolation, which is particularly useful for time series data.\n",
    "dropped_columns_df['aqi_42602'] = dropped_columns_df['aqi_42602'].interpolate(method='time')\n",
    "\n",
    "#3. Mean imputation by category:\n",
    "# If there are still missing values after the above steps, we can use mean imputation based on categories like ‘County’ and ‘date_local’.\n",
    "# Group by relevant categories and fill with mean\n",
    "dropped_columns_df['aqi_42602'] = dropped_columns_df.groupby(['county','date_local'])['aqi_42602'].transform(lambda x: x.fillna(x.mean()))\n",
    "\n",
    "# 4. Overall mean imputation:\n",
    "# As a last resort, fill any remaining missing values with the overall mean.\n",
    "dropped_columns_df['aqi_42602'] = dropped_columns_df['aqi_42602'].fillna(dropped_columns_df['aqi_42602'].mean())\n",
    "\n",
    "# # Check for missing values\n",
    "print(\"Missing values before imputation:\")\n",
    "print(dropped_columns_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DgniAOSHaqYj"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11535,
     "status": "ok",
     "timestamp": 1719957081797,
     "user": {
      "displayName": "Chearine P",
      "userId": "14540736819828601911"
     },
     "user_tz": 240
    },
    "id": "uZyWd8d2atWU",
    "outputId": "d49e4fd9-1711-4367-824a-81945cea79a5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chearine\\AppData\\Local\\Temp\\ipykernel_25228\\2813787990.py:8: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  dropped_columns_df['aqi_88502'] = dropped_columns_df['aqi_88502'].fillna(method='ffill').fillna(method='bfill')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values after imputation:\n",
      "latitude     0\n",
      "longitude    0\n",
      "county       0\n",
      "aqi_42101    0\n",
      "aqi_42401    0\n",
      "aqi_44201    0\n",
      "aqi_42602    0\n",
      "aqi_88502    0\n",
      "aqi_max      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#To fill the missing AQI_88502 score values in the provided code, we used imputation techniques.\n",
    "#Based on the nature of air quality data, which often has temporal and spatial dependencies, we useds a combination of methods.\n",
    "\n",
    "#1. Forward fill and backward fill:\n",
    "# First, we’ll use forward fill and backward fill methods to handle missing values that occur in time series data.\n",
    "\n",
    "# Forward fill and backward fill\n",
    "dropped_columns_df['aqi_88502'] = dropped_columns_df['aqi_88502'].fillna(method='ffill').fillna(method='bfill')\n",
    "\n",
    "#2. Interpolation:\n",
    "#For any remaining missing values, we can use interpolation, which is particularly useful for time series data.\n",
    "dropped_columns_df['aqi_88502'] = dropped_columns_df['aqi_88502'].interpolate(method='time')\n",
    "\n",
    "#3. Mean imputation by category:\n",
    "# If there are still missing values after the above steps, we can use mean imputation based on categories like ‘County’ and ‘date_local’.\n",
    "# Group by relevant categories and fill with mean\n",
    "dropped_columns_df['aqi_88502'] = dropped_columns_df.groupby(['county','date_local'])['aqi_88502'].transform(lambda x: x.fillna(x.mean()))\n",
    "\n",
    "# 4. Overall mean imputation:\n",
    "# As a last resort, fill any remaining missing values with the overall mean.\n",
    "dropped_columns_df['aqi_88502'] = dropped_columns_df['aqi_88502'].fillna(dropped_columns_df['aqi_88502'].mean())\n",
    "\n",
    "# # Check for missing values\n",
    "print(\"Missing values after imputation:\")\n",
    "print(dropped_columns_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "executionInfo": {
     "elapsed": 136,
     "status": "ok",
     "timestamp": 1719963106528,
     "user": {
      "displayName": "Chearine P",
      "userId": "14540736819828601911"
     },
     "user_tz": 240
    },
    "id": "WMaHy0XNwtuG"
   },
   "outputs": [],
   "source": [
    "# Write output file to /Resources folder\n",
    "dropped_columns_df.to_csv(\"Resources/consolidated_seven_ny_counties_filled.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPEoWLpMHeBA50gMQssuTVJ",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
